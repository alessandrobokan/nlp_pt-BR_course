{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "from spacy.lang.pt import Portuguese\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"O rato roeu a roupa do rei de Roma.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = Portuguese()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O\n",
      "rato\n",
      "roeu\n",
      "a\n",
      "roupa\n",
      "do\n",
      "rei\n",
      "de\n",
      "Roma\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence tokenization\n",
    "\n",
    "Consist in break the text into sentences. When performing sentence tokenization, the tokenizer looks for specific characters that fall between sentences, like periods, exclaimation points, and newline characters. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test without pt-BR pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Messi também concorre no Prêmio Puskàs, de gol mais bonito da temporada, pelo toque de cobertura contra o Bétis, em março.\n",
      "* Seus adversários são o colombiano Quintero, pela cobrança de falta pelo River Plate diante do Racing, em fevereiro, e o húngaro Dániel Zsóri, do Debrecen, autor de uma bicicleta contra o Ferencváros.\n",
      "* O brasileiro Matheus Cunha, do RB Leipzig, era um dos 10 indicados, mas ficou fora do trio finalista.\n"
     ]
    }
   ],
   "source": [
    "nlp = Portuguese()\n",
    "\n",
    "# Create the pipeline 'sentencizer' component\n",
    "sentencizer = nlp.create_pipe('sentencizer')\n",
    "\n",
    "# Add the component to the pipeline\n",
    "nlp.add_pipe(sentencizer)\n",
    "\n",
    "text = 'Messi também concorre no Prêmio Puskàs, de gol mais bonito da temporada, pelo toque de cobertura contra o Bétis, em março. Seus adversários são o colombiano Quintero, pela cobrança de falta pelo River Plate diante do Racing, em fevereiro, e o húngaro Dániel Zsóri, do Debrecen, autor de uma bicicleta contra o Ferencváros. O brasileiro Matheus Cunha, do RB Leipzig, era um dos 10 indicados, mas ficou fora do trio finalista.'\n",
    "\n",
    "doc = nlp(text)\n",
    "for sentence in doc.sents:\n",
    "    if sentence.text.strip():\n",
    "        print(\"* %s\" % sentence.text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test with pt-BR pipeline (tokenizer, sentence tokenizer, tagger, parser, NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Messi também concorre no Prêmio Puskàs, de gol mais bonito da temporada, pelo toque de cobertura contra o Bétis, em março.\n",
      "* Seus adversários são o colombiano Quintero, pela cobrança de falta pelo River\n",
      "* Plate diante do Racing, em fevereiro, e o húngaro Dániel Zsóri, do Debrecen, autor de uma bicicleta contra o Ferencváros.\n",
      "* O brasileiro Matheus Cunha, do RB Leipzig, era um dos 10 indicados, mas ficou fora do trio finalista.\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('pt_core_news_sm')\n",
    "\n",
    "text = 'Messi também concorre no Prêmio Puskàs, de gol mais bonito da temporada, pelo toque de cobertura contra o Bétis, em março. Seus adversários são o colombiano Quintero, pela cobrança de falta pelo River Plate diante do Racing, em fevereiro, e o húngaro Dániel Zsóri, do Debrecen, autor de uma bicicleta contra o Ferencváros. O brasileiro Matheus Cunha, do RB Leipzig, era um dos 10 indicados, mas ficou fora do trio finalista.'\n",
    "\n",
    "doc = nlp(text)\n",
    "for sentence in doc.sents:\n",
    "    if sentence.text.strip():\n",
    "        print(\"* %s\" % sentence.text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing stopwords\n",
    "\n",
    "Most text data that we work with is going to contain a lot of words that aren’t actually useful to us. These words, called stopwords, are useful in human speech, but they don’t have much to contribute to data analysis. Removing stopwords helps us eliminate noise and distraction from our text data, and also speeds up the time analysis takes (since there are fewer words to process)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pt-BR stop-words: 413\n",
      "First 20 stop words: ['lá', 'desse', 'porém', 'possível', 'sem', 'pelos', 'estou', 'des', 'posso', 'uns', 'porquanto', 'inicio', 'enquanto', 'tentar', 'essas', 'inclusive', 'só', 'também', 'vários', 'tentaram']\n"
     ]
    }
   ],
   "source": [
    "# List some stopwords\n",
    "stopwords = spacy.lang.pt.stop_words.STOP_WORDS\n",
    "\n",
    "print('Number of pt-BR stop-words: %d' % len(stopwords))\n",
    "\n",
    "print('First 20 stop words: %s' % list(stopwords)[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing stopwords from our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence without stopwords and punctuation marks: [Messi, concorre, Prêmio, Puskàs, gol, bonito, temporada, toque, cobertura, o, Bétis, março]\n"
     ]
    }
   ],
   "source": [
    "nlp = Portuguese()\n",
    "\n",
    "text = 'Messi também concorre no Prêmio Puskàs, de gol mais bonito da temporada, pelo toque de cobertura contra o Bétis, em março.'\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "# filtering stop words\n",
    "sent_no_sw = [token for token in doc if not token.is_stop and not token.is_punct]\n",
    "\n",
    "print(\"Sentence without stopwords and punctuation marks:\", sent_no_sw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I want to add/remove stopwords..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence without stopwords and punctuation marks: [Messi, não, concorre, Prêmio, Puskàs, bonito, temporada]\n"
     ]
    }
   ],
   "source": [
    "nlp = Portuguese()\n",
    "\n",
    "nlp.vocab[\"não\"].is_stop = False\n",
    "nlp.vocab[\"gol\"].is_stop = True\n",
    "\n",
    "text = 'Messi também não concorre no Prêmio Puskàs, de gol mais bonito da temporada'\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "# filtering stop words and punct marks\n",
    "sent_no_sw = [token for token in doc if not token.is_stop and not token.is_punct]\n",
    "\n",
    "print(\"Sentence without stopwords and punctuation marks:\", sent_no_sw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lexicon Normalization\n",
    "\n",
    "Lemmatization is a way of dealing with the fact that while words like connect, connection, connecting, connected, etc. aren’t exactly the same, they all have the same essential meaning: connect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+\n",
      "|    Text   |   Lemma   |\n",
      "+-----------+-----------+\n",
      "|     Na    |     Na    |\n",
      "| categoria | categoria |\n",
      "|     de    |     de    |\n",
      "|  técnicos |  técnico  |\n",
      "|     de    |     de    |\n",
      "|  equipes  |  equipar  |\n",
      "| femininas |  feminino |\n",
      "|     ,     |     ,     |\n",
      "|    duas   |    dois   |\n",
      "|  mulheres |   mulher  |\n",
      "|  disputam |  disputar |\n",
      "|    com    |    com    |\n",
      "|     um    |     um    |\n",
      "|   homem   |   homem   |\n",
      "|     .     |     .     |\n",
      "+-----------+-----------+\n"
     ]
    }
   ],
   "source": [
    "nlp = Portuguese()\n",
    "\n",
    "doc = nlp(\"Na categoria de técnicos de equipes femininas, duas mulheres disputam com um homem.\")\n",
    "\n",
    "x = PrettyTable()\n",
    "x.field_names = [\"Text\", \"Lemma\"]\n",
    "\n",
    "for token in doc:\n",
    "    x.add_row([token.text, token.lemma_])\n",
    "    \n",
    "print(x)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming involves simply lopping off easily-identified prefixes and suffixes to produce what’s often the simplest version of a word. Connection, for example, would have the -ion suffix removed and be correctly reduced to connect. However, spaCy **doesn't contain any function for stemming** as it relies on lemmatization only. Therefore, in this section, we will use NLTK for stemming. You need to use NLTK stemmer\n",
    "\n",
    "**OBS:** lemmatization is more precise than stemming!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part of Speech (POS) Tagging\n",
    "\n",
    "A word’s part of speech defines its function within a sentence. A noun, for example, identifies an object. \n",
    "An adjective describes an object. A verb describes action. Identifying and tagging each word’s part of \n",
    "speech in the context of a sentence is called Part-of-Speech Tagging, or POS Tagging.\n",
    "\n",
    "We’ll need to import its `pt_core_news_sm`model, because that contains the dictionary and grammatical \n",
    "information required to do this analysis. Then all we need to do is load this model with .load() and \n",
    "loop through our new docs variable, identifying the part of speech for each word using .pos_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------------------------+\n",
      "|  Text |  POS  | Tag                      |\n",
      "+-------+-------+--------------------------+\n",
      "|   O   |  DET  | <artd>|ART|M|S|@>N       |\n",
      "|  rato |  NOUN | <np-def>|N|M|S|@SUBJ>    |\n",
      "|  roeu |  VERB | <mv>|V|PR|3S|IND|@FS-STA |\n",
      "|   a   |  DET  | <artd>|ART|F|S|@>N       |\n",
      "| roupa |  NOUN | <np-def>|N|F|S|@<ACC     |\n",
      "|   do  |  DET  | <artd>|ART|M|P|@>N       |\n",
      "|  rei  |  NOUN | <np-def>|N|M|S|@<ACC     |\n",
      "|   de  |  ADP  | PRP|@N<                  |\n",
      "|  Roma | PROPN | PROP|M|S|@P<             |\n",
      "|   .   | PUNCT | PU|@PU                   |\n",
      "+-------+-------+--------------------------+\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('pt_core_news_sm')\n",
    "\n",
    "text = \"O rato roeu a roupa do rei de Roma.\"\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "x = PrettyTable()\n",
    "x.field_names = [\"Text\", \"POS\", \"Tag\"]\n",
    "x.align[\"Tag\"] = \"l\"\n",
    "\n",
    "for token in doc:\n",
    "    x.add_row([token.text, token.pos_, token.tag_])\n",
    "    \n",
    "print(x)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------------------------+\n",
      "|  Text |  POS  | Tag                      |\n",
      "+-------+-------+--------------------------+\n",
      "|   Eu  |  PRON | PERS|M|1S|NOM|@SUBJ>     |\n",
      "| gosto |  VERB | <mv>|V|PR|1S|IND|@FS-STA |\n",
      "|   do  |  DET  | <artd>|ART|M|S|@>N       |\n",
      "| gosto |  NOUN | <np-idf>|N|M|S|@<ACC     |\n",
      "|   da  |  ADP  | PRP|@N<                  |\n",
      "|  uva  |  NOUN | <np-idf>|N|F|S|@P<       |\n",
      "|   .   | PUNCT | PU|@PU                   |\n",
      "+-------+-------+--------------------------+\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('pt_core_news_sm')\n",
    "\n",
    "doc = nlp(\"Eu gosto do gosto da uva.\")\n",
    "\n",
    "x = PrettyTable()\n",
    "x.field_names = [\"Text\", \"POS\", \"Tag\"]\n",
    "x.align[\"Tag\"] = \"l\"\n",
    "\n",
    "for token in doc:\n",
    "    x.add_row([token.text, token.pos_, token.tag_])\n",
    "    \n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition (NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('pt_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"O Fantástico teve acesso exclusivo à investigação da Aeronáutica que apontou que o sargento Manoel Silva Rodrigues, preso na Espanha em junho com 39 kg de cocaína, entrou no avião ainda desligado e não passou a bagagem pelos procedimentos de segurança previstos. O militar estava na comitiva presidencial que levava o presidente Jair Bolsonaro – que estava em outra aeronave – ao encontro do G20 no Japão.\"\n",
    "\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">O \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Fantástico\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
       "</mark>\n",
       " teve acesso exclusivo à investigação da \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Aeronáutica\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " que apontou que o sargento \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Manoel Silva Rodrigues\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", preso na \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Espanha\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " em junho com 39 kg de cocaína, entrou no avião ainda desligado e não passou a bagagem pelos procedimentos de segurança previstos. O militar estava na comitiva presidencial que levava o presidente \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Jair Bolsonaro\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " – que estava em outra aeronave – ao encontro do \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    G20\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " no \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Japão\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ".</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style = \"ent\",jupyter = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependency Parsing\n",
    "\n",
    "Depenency parsing is a language processing technique that allows us to better determine the meaning \n",
    "of a sentence by analyzing how it’s constructed to determine how the individual words relate to each other.\n",
    "\n",
    "Consider, for example, the sentence “Bill throws the ball.” We have two nouns (Bill and ball) \n",
    "and one verb (throws). But we can’t just look at these words individually, or we may end up thinking that \n",
    "the ball is throwing Bill! To understand the sentence correctly, we need to look at the word order \n",
    "and sentence structure, not just the words and their parts of speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('pt_core_news_sm')\n",
    "\n",
    "text = \"O rato roeu a roupa do rei de Roma.\"\n",
    "\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"pt\" id=\"14e3f6f9fd9a490cb96f10b75e90da0e-0\" class=\"displacy\" width=\"1625\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">O</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">rato</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">roeu</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">roupa</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">do</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">rei</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">de</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">Roma.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-14e3f6f9fd9a490cb96f10b75e90da0e-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-14e3f6f9fd9a490cb96f10b75e90da0e-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-14e3f6f9fd9a490cb96f10b75e90da0e-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-14e3f6f9fd9a490cb96f10b75e90da0e-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,179.0 L237,167.0 253,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-14e3f6f9fd9a490cb96f10b75e90da0e-0-2\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-14e3f6f9fd9a490cb96f10b75e90da0e-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,179.0 L587,167.0 603,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-14e3f6f9fd9a490cb96f10b75e90da0e-0-3\" stroke-width=\"2px\" d=\"M420,177.0 C420,2.0 750.0,2.0 750.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-14e3f6f9fd9a490cb96f10b75e90da0e-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M750.0,179.0 L758.0,167.0 742.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-14e3f6f9fd9a490cb96f10b75e90da0e-0-4\" stroke-width=\"2px\" d=\"M945,177.0 C945,89.5 1095.0,89.5 1095.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-14e3f6f9fd9a490cb96f10b75e90da0e-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,179.0 L937,167.0 953,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-14e3f6f9fd9a490cb96f10b75e90da0e-0-5\" stroke-width=\"2px\" d=\"M770,177.0 C770,2.0 1100.0,2.0 1100.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-14e3f6f9fd9a490cb96f10b75e90da0e-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1100.0,179.0 L1108.0,167.0 1092.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-14e3f6f9fd9a490cb96f10b75e90da0e-0-6\" stroke-width=\"2px\" d=\"M1295,177.0 C1295,89.5 1445.0,89.5 1445.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-14e3f6f9fd9a490cb96f10b75e90da0e-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1295,179.0 L1287,167.0 1303,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-14e3f6f9fd9a490cb96f10b75e90da0e-0-7\" stroke-width=\"2px\" d=\"M1120,177.0 C1120,2.0 1450.0,2.0 1450.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-14e3f6f9fd9a490cb96f10b75e90da0e-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1450.0,179.0 L1458.0,167.0 1442.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style=\"dep\", jupyter= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
